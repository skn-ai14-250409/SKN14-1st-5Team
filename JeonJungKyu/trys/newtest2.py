import streamlit as st
import mysql.connector
from dotenv import load_dotenv
import os
import requests
from bs4 import BeautifulSoup
import openai
from gtts import gTTS
from io import BytesIO

# â”€â”€ 1) .env ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
openai.api_key = os.getenv("OPEN_AI_API")

# â”€â”€ 2) ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_CONFIG = {
    'host': os.getenv('DB_HOST'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'database': os.getenv('DB_NAME')
}
HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/89.0.4389.114 Safari/537.36"
    )
}


# â”€â”€ 3) ìœ í‹¸: HTML ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_html(soup: BeautifulSoup):
    for tag in soup.select("script, style, aside, .ad, .related-article"):
        tag.decompose()


# â”€â”€ 4) ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_html_text(url: str) -> str:
    try:
        res = requests.get(url, headers=HEADERS, timeout=10)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        clean_html(soup)
        return soup.get_text(separator="\n")
    except Exception:
        return ""


# â”€â”€ 5) ìš”ì•½í•˜ê¸° (ê³µë°± ì •ë¦¬ ì¶”ê°€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_text(text: str) -> str:
    cleaned_text = "\n".join(
        line.strip() for line in text.splitlines() if line.strip()
    )

    prompt = f"""
    ë‹¤ìŒ ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì¤‘ìš” ê¸°ì‚¬ ë‚´ìš©ë§Œ 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜.
    ë©”ë‰´, ê´‘ê³ , ëŒ“ê¸€, ì €ì‘ê¶Œ ë¬¸êµ¬ëŠ” ë¬´ì‹œí•´ì¤˜.

    {cleaned_text}
    """
    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
    )
    return resp.choices[0].message.content.strip()


# â”€â”€ 6) Streamlit ì•± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“° ë‰´ìŠ¤ ìš”ì•½ & TTS ë³€í™˜")

st.caption("ë„¤ì´ë²„ ë‰´ìŠ¤ ì›ë¬¸ ë§í¬ë¥¼ ìš”ì•½í•˜ê³  ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")

if st.button("ğŸ“ ë‰´ìŠ¤ ìš”ì•½ ì‹œì‘"):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute("SELECT originallink FROM naver_news")
        urls = [r[0] for r in cur.fetchall()]
        cur.close()
        conn.close()
    except Exception as e:
        st.error(f"DB ì˜¤ë¥˜: {e}")
        urls = []

    for idx, url in enumerate(urls, start=1):
        with st.container():
            st.markdown(f"### ğŸ”— ë‰´ìŠ¤ #{idx}")
            st.markdown(f"[{url}]({url})")

            article = get_html_text(url)
            if not article:
                st.error("â— ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
                continue

            summary = summarize_text(article)

            if "ë¬´ë‹¨ ì „ì¬" in summary or "ì¬ë°°í¬ ê¸ˆì§€" in summary:
                st.warning("ğŸš« í•´ë‹¹ ê¸°ì‚¬ëŠ” TTSê°€ ë¶ˆê°€í•©ë‹ˆë‹¤. (ë¬´ë‹¨ ì „ì¬ ë¬¸êµ¬ í¬í•¨)")
                continue

            st.success("âœ¨ ìš”ì•½ ê²°ê³¼")
            st.write(summary)

            tts = gTTS(text=summary, lang="ko")
            buf = BytesIO()
            tts.write_to_fp(buf)

            st.audio(buf.getvalue(), format="audio/mp3")

        st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
